{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Sub-Cellular Localization Pipeline - Jupyter Notebook\n",
    "\n",
    "This notebook demonstrates how to use the protein localization pipeline in an interactive Jupyter environment.\n",
    "\n",
    "**You do NOT need to copy-paste all the code!** Simply import the modules and use them as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, ensure you have installed all dependencies:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the scripts directory to the Python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust this path to point to your scripts directory\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'scripts'))\n",
    "\n",
    "print(\"✓ Path configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Run Complete Pipeline (Easiest)\n",
    "\n",
    "This is the simplest way - just import and run the complete pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import ProteinLocalizationPipeline\n",
    "\n",
    "# Configure your paths\n",
    "input_dir = \"D:\\\\5TH_SEM\\\\CELLULAR\\\\input\"  # Your TIFF files location\n",
    "output_dir = \"D:\\\\5TH_SEM\\\\CELLULAR\\\\output\"  # Where to save results\n",
    "\n",
    "# Create and run pipeline\n",
    "pipeline = ProteinLocalizationPipeline(input_dir, output_dir)\n",
    "model, history = pipeline.run_complete_pipeline(epochs=20)\n",
    "\n",
    "print(\"\\n✓ Pipeline completed!\")\n",
    "print(f\"Final accuracy: {history['test_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Step-by-Step Execution\n",
    "\n",
    "If you want more control, you can run each step individually:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load TIFF Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiff_loader import TIFFLoader\n",
    "\n",
    "# Initialize loader\n",
    "loader = TIFFLoader(\"D:\\\\5TH_SEM\\\\CELLULAR\\\\input\")\n",
    "\n",
    "# Scan for TIFF files\n",
    "tiff_files = loader.scan_directory()\n",
    "\n",
    "print(f\"Found {len(tiff_files)} TIFF files\")\n",
    "\n",
    "# Load first image as example\n",
    "if tiff_files:\n",
    "    first_image = loader.load_single_tiff(tiff_files[0])\n",
    "    info = loader.get_image_info(first_image)\n",
    "    print(\"\\nFirst image info:\")\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preprocess and Segment Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import ImagePreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ImagePreprocessor()\n",
    "\n",
    "# Process the first image\n",
    "if tiff_files:\n",
    "    image = loader.load_single_tiff(tiff_files[0])\n",
    "    labeled_regions, features = preprocessor.process_image(image)\n",
    "    \n",
    "    print(f\"Detected {len(features)} regions\")\n",
    "    print(\"\\nFirst region features:\")\n",
    "    for key, value in features[0].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Visualize segmentation\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image if image.ndim == 2 else image.max(axis=0), cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(labeled_regions, cmap='tab20')\n",
    "    plt.title('Segmented Regions')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Construct Graph from Segmented Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_construction import GraphConstructor\n",
    "\n",
    "# Initialize constructor\n",
    "constructor = GraphConstructor()\n",
    "\n",
    "# Create graph\n",
    "graph = constructor.create_graph_from_regions(features, distance_threshold=50.0)\n",
    "\n",
    "# Print graph statistics\n",
    "stats = constructor.get_graph_statistics(graph)\n",
    "print(\"Graph statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Get feature matrix\n",
    "feature_matrix = constructor.get_node_feature_matrix(graph)\n",
    "print(f\"\\nFeature matrix shape: {feature_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import GraphVisualizer\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = GraphVisualizer()\n",
    "\n",
    "# Visualize graph\n",
    "fig = visualizer.visualize_graph(\n",
    "    graph, \n",
    "    predictions=None,  # No predictions yet\n",
    "    title=\"Protein Location Graph\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Visualize features\n",
    "fig = visualizer.visualize_features(\n",
    "    feature_matrix,\n",
    "    labels=[f\"Node {i+1}\" for i in range(feature_matrix.shape[0])],\n",
    "    feature_names=['Area', 'Intensity', 'Eccentricity', 'Solidity']\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train Graph-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training import GraphCNN, ModelTrainer\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# For this example, we'll create some dummy data\n",
    "# In practice, you would prepare your actual data\n",
    "\n",
    "# Model configuration\n",
    "num_features = 4  # area, intensity, eccentricity, solidity\n",
    "num_classes = 5   # nucleus, mitochondria, ER, golgi, cytoplasm\n",
    "\n",
    "# Initialize model\n",
    "model = GraphCNN(num_features, num_classes)\n",
    "trainer = ModelTrainer(model, device='cpu')\n",
    "trainer.setup_training(learning_rate=0.001)\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(\"\\nModel ready for training!\")\n",
    "print(\"To train with your data, prepare DataLoader objects and call:\")\n",
    "print(\"  history = trainer.train(train_loader, test_loader, num_epochs=50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can make predictions\n",
    "\n",
    "# Example prediction code (requires trained model)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     output = model(test_data)\n",
    "#     predictions = output.argmax(dim=1)\n",
    "\n",
    "# Class names\n",
    "class_names = ['Nucleus', 'Mitochondria', 'Endoplasmic Reticulum', 'Golgi', 'Cytoplasm']\n",
    "\n",
    "print(\"Prediction classes:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Use Pre-trained Model (If Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "import torch\n",
    "from model_training import GraphCNN, ModelTrainer\n",
    "\n",
    "# Initialize model\n",
    "model = GraphCNN(num_features=4, num_classes=5)\n",
    "trainer = ModelTrainer(model)\n",
    "\n",
    "# Load trained weights (if you have them)\n",
    "model_path = \"output/models/graph_cnn.pt\"\n",
    "if os.path.exists(model_path):\n",
    "    trainer.load_model(model_path)\n",
    "    print(\"✓ Pre-trained model loaded!\")\n",
    "else:\n",
    "    print(\"No pre-trained model found. Train one using the pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Demo with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick demo with synthetic data\n",
    "from pipeline import ProteinLocalizationPipeline\n",
    "\n",
    "# This will automatically generate synthetic data if no real data is found\n",
    "pipeline = ProteinLocalizationPipeline(\n",
    "    input_dir=\"./nonexistent\",  # Use fake path to trigger synthetic data\n",
    "    output_dir=\"./demo_output\"\n",
    ")\n",
    "\n",
    "print(\"Running demo with synthetic data...\")\n",
    "model, history = pipeline.run_complete_pipeline(epochs=10)\n",
    "\n",
    "print(\"\\n✓ Demo completed!\")\n",
    "print(f\"Final test accuracy: {history['test_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import GraphVisualizer\n",
    "\n",
    "visualizer = GraphVisualizer()\n",
    "\n",
    "# Plot training history\n",
    "fig = visualizer.plot_training_history(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**You have three options:**\n",
    "\n",
    "1. **Easiest**: Use `pipeline.run_complete_pipeline()` - runs everything automatically\n",
    "2. **More Control**: Import individual modules and run step-by-step\n",
    "3. **Custom**: Modify the code in the scripts directory for your specific needs\n",
    "\n",
    "**You do NOT need to copy-paste code!** Just import the modules as shown above.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Ensure your TIFF files are in the input directory\n",
    "2. Run the complete pipeline or execute steps individually\n",
    "3. Check the output directory for results:\n",
    "   - `graphs/` - Graph structures\n",
    "   - `models/` - Trained models\n",
    "   - `visualizations/` - Result images\n",
    "\n",
    "### Need Help?\n",
    "\n",
    "- See `README.md` for detailed documentation\n",
    "- See `docs/QUICKSTART.md` for quick setup guide\n",
    "- See `docs/PROJECT_OVERVIEW.md` for technical details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
