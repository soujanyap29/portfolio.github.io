{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Sub-Cellular Localization in Neurons\n",
    "## Final Pipeline - Complete Demonstration\n",
    "\n",
    "**Course:** Machine Learning and Deep Learning  \n",
    "**Project:** Automated Protein Localization using CNN + GNN  \n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the complete pipeline for protein sub-cellular localization analysis from TIFF microscopy images.\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Image Loading** - Load and preprocess TIFF images\n",
    "2. **Segmentation** - Apply biological segmentation (SLIC/U-Net/Watershed)\n",
    "3. **CNN Classification** - VGG16-based global feature extraction\n",
    "4. **Graph Construction** - Build superpixel-based graph\n",
    "5. **GNN Classification** - Graph neural network spatial reasoning\n",
    "6. **Model Fusion** - Combine predictions from CNN and GNN\n",
    "7. **Evaluation** - Compute metrics and generate reports\n",
    "8. **Visualization** - Create publication-quality figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import all necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Add backend to path\n",
    "backend_path = os.path.abspath('../backend')\n",
    "if backend_path not in sys.path:\n",
    "    sys.path.insert(0, backend_path)\n",
    "\n",
    "# Project imports\n",
    "from config import *\n",
    "from image_loader import TIFFLoader, ImageAugmentation\n",
    "from segmentation import SegmentationModule, save_segmentation\n",
    "from cnn_model import VGG16Classifier, ResNetClassifier, EfficientNetClassifier\n",
    "from gnn_model import GraphConstructor, GNNClassifier, GCNModel, GATModel, GraphSAGEModel\n",
    "from model_fusion import ModelFusion, AdaptiveFusion\n",
    "from evaluation import EvaluationMetrics, compute_colocalization_metrics\n",
    "from visualization import ScientificVisualizer\n",
    "from pipeline import ProteinLocalizationPipeline\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ“ All imports successful\")\n",
    "print(f\"âœ“ Backend path: {backend_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up paths and parameters for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory setup\n",
    "INPUT_DIR = \"/mnt/d/5TH_SEM/CELLULAR/input\"\n",
    "OUTPUT_DIR = \"/mnt/d/5TH_SEM/CELLULAR/output\"\n",
    "GRAPHS_DIR = os.path.join(OUTPUT_DIR, \"graphs\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(GRAPHS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"results\", \"segmented\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"results\", \"predictions\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"results\", \"reports\"), exist_ok=True)\n",
    "\n",
    "# Display configuration\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Input Directory: {INPUT_DIR}\")\n",
    "print(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Graphs Directory: {GRAPHS_DIR}\")\n",
    "print(f\"\\nProtein Classes ({len(PROTEIN_CLASSES)}):\")\n",
    "for i, cls in enumerate(PROTEIN_CLASSES, 1):\n",
    "    print(f\"  {i}. {cls}\")\n",
    "print(f\"\\nSegmentation Method: {SEGMENTATION_METHOD}\")\n",
    "print(f\"Image Size: {IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demo: Single Image Analysis\n",
    "\n",
    "Let's demonstrate the pipeline with a single image (or create a synthetic example if no real data is available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Synthetic Test Image\n",
    "\n",
    "For demonstration purposes, we'll create a synthetic neuronal image if no real TIFF files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_neuron_image(size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Create a synthetic neuronal microscopy image for demonstration.\n",
    "    Simulates different cellular compartments with varying intensities.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    \n",
    "    image = np.zeros(size, dtype=np.float32)\n",
    "    \n",
    "    # Create nucleus (bright center)\n",
    "    cy, cx = size[0] // 2, size[1] // 2\n",
    "    radius = 80\n",
    "    y, x = np.ogrid[:size[0], :size[1]]\n",
    "    mask_nucleus = (x - cx)**2 + (y - cy)**2 <= radius**2\n",
    "    image[mask_nucleus] = 0.9\n",
    "    \n",
    "    # Add cytoplasm (medium intensity)\n",
    "    radius_cytoplasm = 200\n",
    "    mask_cytoplasm = (x - cx)**2 + (y - cy)**2 <= radius_cytoplasm**2\n",
    "    image[mask_cytoplasm & ~mask_nucleus] = 0.5\n",
    "    \n",
    "    # Add some mitochondria-like structures (bright spots)\n",
    "    np.random.seed(42)\n",
    "    for _ in range(15):\n",
    "        my, mx = np.random.randint(cy-150, cy+150), np.random.randint(cx-150, cx+150)\n",
    "        mr = np.random.randint(10, 20)\n",
    "        mask_mito = (x - mx)**2 + (y - my)**2 <= mr**2\n",
    "        image[mask_mito] = np.random.uniform(0.7, 0.95)\n",
    "    \n",
    "    # Apply Gaussian smoothing\n",
    "    image = gaussian_filter(image, sigma=2)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 0.02, size)\n",
    "    image = np.clip(image + noise, 0, 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Create synthetic image\n",
    "synthetic_image = create_synthetic_neuron_image()\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(synthetic_image, cmap='gray')\n",
    "ax.set_title('Synthetic Neuronal Microscopy Image', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(GRAPHS_DIR, 'demo_synthetic_image.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Synthetic image created: shape={synthetic_image.shape}, dtype={synthetic_image.dtype}\")\n",
    "print(f\"  Min intensity: {synthetic_image.min():.3f}\")\n",
    "print(f\"  Max intensity: {synthetic_image.max():.3f}\")\n",
    "print(f\"  Mean intensity: {synthetic_image.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Image Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loader\n",
    "loader = TIFFLoader()\n",
    "\n",
    "# For demonstration, use synthetic image\n",
    "# In production, replace with: image = loader.load_tiff('path/to/real/image.tif')\n",
    "image = synthetic_image.copy()\n",
    "\n",
    "# Normalize\n",
    "image_normalized = loader.normalize_image(image)\n",
    "\n",
    "# Prepare for CNN (resize and add channels)\n",
    "image_for_cnn = loader.preprocess_for_model(image_normalized, size=IMAGE_SIZE)\n",
    "\n",
    "print(f\"âœ“ Image preprocessing complete\")\n",
    "print(f\"  Original shape: {image.shape}\")\n",
    "print(f\"  Normalized shape: {image_normalized.shape}\")\n",
    "print(f\"  CNN input shape: {image_for_cnn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize segmentation module\n",
    "segmentation_module = SegmentationModule(method=SEGMENTATION_METHOD)\n",
    "\n",
    "# Perform segmentation\n",
    "print(f\"Performing {SEGMENTATION_METHOD} segmentation...\")\n",
    "segments = segmentation_module.segment(\n",
    "    image_normalized,\n",
    "    n_segments=SLIC_N_SEGMENTS,\n",
    "    compactness=SLIC_COMPACTNESS\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Segmentation complete\")\n",
    "print(f\"  Number of segments: {segments.max() + 1}\")\n",
    "print(f\"  Segment labels range: [{segments.min()}, {segments.max()}]\")\n",
    "\n",
    "# Visualize segmentation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(image_normalized, cmap='gray')\n",
    "axes[0].set_title('Original Image', fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Segmentation\n",
    "axes[1].imshow(segments, cmap='nipy_spectral')\n",
    "axes[1].set_title(f'{SEGMENTATION_METHOD} Segmentation', fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "axes[2].imshow(image_normalized, cmap='gray')\n",
    "axes[2].imshow(segments, cmap='nipy_spectral', alpha=0.4)\n",
    "axes[2].set_title('Overlay', fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(GRAPHS_DIR, 'demo_segmentation.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 CNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN classifier\n",
    "print(\"Initializing VGG16 CNN classifier...\")\n",
    "cnn_classifier = VGG16Classifier(num_classes=len(PROTEIN_CLASSES), input_shape=(*IMAGE_SIZE, 3))\n",
    "\n",
    "# Note: In production, you would load pre-trained weights here\n",
    "# cnn_classifier.model.load_weights('path/to/weights.h5')\n",
    "\n",
    "# For demonstration, we'll simulate predictions\n",
    "# In production: cnn_class, cnn_probs = cnn_classifier.predict(image_for_cnn[0])\n",
    "\n",
    "# Simulate CNN prediction (for demo without trained model)\n",
    "np.random.seed(42)\n",
    "cnn_probs = np.random.dirichlet(np.ones(len(PROTEIN_CLASSES)) * 2)  # Generate realistic probabilities\n",
    "cnn_probs[0] = 0.65  # Bias towards Nucleus for demo\n",
    "cnn_probs = cnn_probs / cnn_probs.sum()  # Normalize\n",
    "cnn_class = np.argmax(cnn_probs)\n",
    "\n",
    "print(f\"âœ“ CNN classification complete\")\n",
    "print(f\"  Predicted class: {PROTEIN_CLASSES[cnn_class]}\")\n",
    "print(f\"  Confidence: {cnn_probs[cnn_class]:.3f}\")\n",
    "print(f\"\\n  Probability distribution:\")\n",
    "for i, (cls, prob) in enumerate(zip(PROTEIN_CLASSES, cnn_probs)):\n",
    "    print(f\"    {cls:25s}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph constructor\n",
    "graph_constructor = GraphConstructor()\n",
    "\n",
    "# Extract superpixel features\n",
    "print(\"Extracting superpixel features...\")\n",
    "features = graph_constructor.extract_superpixel_features(image_normalized, segments)\n",
    "\n",
    "print(f\"âœ“ Feature extraction complete\")\n",
    "print(f\"  Feature matrix shape: {features.shape}\")\n",
    "print(f\"  Number of features per node: {features.shape[1]}\")\n",
    "print(f\"\\n  Feature statistics:\")\n",
    "feature_names = ['Mean Intensity', 'Std Intensity', 'Min Intensity', 'Max Intensity',\n",
    "                'Area', 'Perimeter', 'Eccentricity', 'Solidity',\n",
    "                'Centroid X', 'Centroid Y', 'Entropy']\n",
    "for i, name in enumerate(feature_names[:5]):  # Show first 5\n",
    "    print(f\"    {name:20s}: mean={features[:, i].mean():.3f}, std={features[:, i].std():.3f}\")\n",
    "\n",
    "# Build adjacency matrix\n",
    "print(\"\\nBuilding graph adjacency...\")\n",
    "adjacency = graph_constructor.build_adjacency(segments, k_neighbors=5)\n",
    "\n",
    "print(f\"âœ“ Graph construction complete\")\n",
    "print(f\"  Adjacency matrix shape: {adjacency.shape}\")\n",
    "print(f\"  Number of edges: {np.sum(adjacency) // 2}\")\n",
    "print(f\"  Average degree: {np.sum(adjacency, axis=1).mean():.2f}\")\n",
    "\n",
    "# Create graph data object\n",
    "graph_data = graph_constructor.create_graph_data(features, adjacency)\n",
    "print(f\"âœ“ Graph data object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 GNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GNN classifier\n",
    "print(\"Initializing GNN classifier (GCN)...\")\n",
    "gnn_classifier = GNNClassifier(\n",
    "    model_type=\"GCN\",\n",
    "    in_channels=features.shape[1],\n",
    "    hidden_channels=GNN_HIDDEN_DIM,\n",
    "    num_classes=len(PROTEIN_CLASSES),\n",
    "    num_layers=GNN_NUM_LAYERS,\n",
    "    dropout=GNN_DROPOUT\n",
    ")\n",
    "\n",
    "# Note: In production, you would load pre-trained weights here\n",
    "# gnn_classifier.model.load_state_dict(torch.load('path/to/weights.pt'))\n",
    "\n",
    "# For demonstration, simulate predictions\n",
    "# In production: gnn_class, gnn_probs = gnn_classifier.predict(graph_data)\n",
    "\n",
    "# Simulate GNN prediction (for demo without trained model)\n",
    "np.random.seed(43)\n",
    "gnn_probs = np.random.dirichlet(np.ones(len(PROTEIN_CLASSES)) * 2)\n",
    "gnn_probs[0] = 0.58  # Bias towards Nucleus for demo\n",
    "gnn_probs = gnn_probs / gnn_probs.sum()\n",
    "gnn_class = np.argmax(gnn_probs)\n",
    "\n",
    "print(f\"âœ“ GNN classification complete\")\n",
    "print(f\"  Predicted class: {PROTEIN_CLASSES[gnn_class]}\")\n",
    "print(f\"  Confidence: {gnn_probs[gnn_class]:.3f}\")\n",
    "print(f\"\\n  Probability distribution:\")\n",
    "for i, (cls, prob) in enumerate(zip(PROTEIN_CLASSES, gnn_probs)):\n",
    "    print(f\"    {cls:25s}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Model Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse predictions\n",
    "print(\"Fusing CNN and GNN predictions...\")\n",
    "\n",
    "# Weighted fusion (60% CNN, 40% GNN)\n",
    "fused_class, fused_probs = ModelFusion.late_fusion_weighted(\n",
    "    cnn_probs, gnn_probs, cnn_weight=0.6, gnn_weight=0.4\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Model fusion complete\")\n",
    "print(f\"\\n=== FINAL PREDICTION ===\")\n",
    "print(f\"  Predicted class: {PROTEIN_CLASSES[fused_class]}\")\n",
    "print(f\"  Confidence: {fused_probs[fused_class]:.3f}\")\n",
    "print(f\"\\n  Comparison:\")\n",
    "print(f\"    CNN:   {PROTEIN_CLASSES[cnn_class]:15s} ({cnn_probs[cnn_class]:.3f})\")\n",
    "print(f\"    GNN:   {PROTEIN_CLASSES[gnn_class]:15s} ({gnn_probs[gnn_class]:.3f})\")\n",
    "print(f\"    Fused: {PROTEIN_CLASSES[fused_class]:15s} ({fused_probs[fused_class]:.3f})\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "models = ['CNN', 'GNN', 'Fused']\n",
    "probs_list = [cnn_probs, gnn_probs, fused_probs]\n",
    "colors_list = [['#3498db' if i != cnn_class else '#e74c3c' for i in range(len(PROTEIN_CLASSES))],\n",
    "               ['#3498db' if i != gnn_class else '#e74c3c' for i in range(len(PROTEIN_CLASSES))],\n",
    "               ['#3498db' if i != fused_class else '#e74c3c' for i in range(len(PROTEIN_CLASSES))]]\n",
    "\n",
    "for ax, model, probs, colors in zip(axes, models, probs_list, colors_list):\n",
    "    ax.bar(range(len(PROTEIN_CLASSES)), probs, color=colors, alpha=0.8)\n",
    "    ax.set_xlabel('Protein Localization Class', fontweight='bold')\n",
    "    ax.set_ylabel('Probability', fontweight='bold')\n",
    "    ax.set_title(f'{model} Predictions', fontweight='bold', fontsize=14)\n",
    "    ax.set_xticks(range(len(PROTEIN_CLASSES)))\n",
    "    ax.set_xticklabels(PROTEIN_CLASSES, rotation=45, ha='right')\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(GRAPHS_DIR, 'demo_model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Visualization Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = ScientificVisualizer(dpi=DPI)\n",
    "\n",
    "print(\"Generating scientific visualizations...\")\n",
    "\n",
    "# 1. Image overlay\n",
    "overlay_path = os.path.join(GRAPHS_DIR, 'demo_overlay.png')\n",
    "visualizer.plot_image_overlay(image_normalized, segments, overlay_path,\n",
    "                              title=\"Protein Localization Analysis\")\n",
    "print(f\"âœ“ Overlay visualization saved: {overlay_path}\")\n",
    "\n",
    "# 2. Probability distribution\n",
    "prob_path = os.path.join(GRAPHS_DIR, 'demo_probabilities.png')\n",
    "EvaluationMetrics.plot_probability_distribution(\n",
    "    fused_probs, PROTEIN_CLASSES, prob_path, fused_class\n",
    ")\n",
    "print(f\"âœ“ Probability plot saved: {prob_path}\")\n",
    "\n",
    "# 3. Graph network visualization\n",
    "graph_path = os.path.join(GRAPHS_DIR, 'demo_graph_network.png')\n",
    "visualizer.plot_graph_visualization(\n",
    "    adjacency, features, graph_path,\n",
    "    title=\"Superpixel Graph Network\"\n",
    ")\n",
    "print(f\"âœ“ Graph visualization saved: {graph_path}\")\n",
    "\n",
    "# 4. Compartment map\n",
    "compartment_path = os.path.join(GRAPHS_DIR, 'demo_compartments.png')\n",
    "visualizer.plot_compartment_map(segments, compartment_path)\n",
    "print(f\"âœ“ Compartment map saved: {compartment_path}\")\n",
    "\n",
    "print(f\"\\nâœ“ All visualizations generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Generate JSON Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive report\n",
    "report = {\n",
    "    \"filename\": \"demo_synthetic_image.tif\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"segmentation\": {\n",
    "        \"method\": SEGMENTATION_METHOD,\n",
    "        \"num_segments\": int(segments.max() + 1),\n",
    "        \"parameters\": {\n",
    "            \"n_segments\": SLIC_N_SEGMENTS,\n",
    "            \"compactness\": SLIC_COMPACTNESS\n",
    "        }\n",
    "    },\n",
    "    \"cnn\": {\n",
    "        \"model\": \"VGG16\",\n",
    "        \"predicted_class\": PROTEIN_CLASSES[cnn_class],\n",
    "        \"predicted_class_index\": int(cnn_class),\n",
    "        \"confidence\": float(cnn_probs[cnn_class]),\n",
    "        \"probabilities\": {PROTEIN_CLASSES[i]: float(cnn_probs[i]) \n",
    "                         for i in range(len(PROTEIN_CLASSES))}\n",
    "    },\n",
    "    \"gnn\": {\n",
    "        \"model\": \"GCN\",\n",
    "        \"predicted_class\": PROTEIN_CLASSES[gnn_class],\n",
    "        \"predicted_class_index\": int(gnn_class),\n",
    "        \"confidence\": float(gnn_probs[gnn_class]),\n",
    "        \"probabilities\": {PROTEIN_CLASSES[i]: float(gnn_probs[i])\n",
    "                         for i in range(len(PROTEIN_CLASSES))}\n",
    "    },\n",
    "    \"fused\": {\n",
    "        \"method\": \"weighted_late_fusion\",\n",
    "        \"weights\": {\"cnn\": 0.6, \"gnn\": 0.4},\n",
    "        \"predicted_class\": PROTEIN_CLASSES[fused_class],\n",
    "        \"predicted_class_index\": int(fused_class),\n",
    "        \"confidence\": float(fused_probs[fused_class]),\n",
    "        \"probabilities\": {PROTEIN_CLASSES[i]: float(fused_probs[i])\n",
    "                         for i in range(len(PROTEIN_CLASSES))}\n",
    "    },\n",
    "    \"visualizations\": {\n",
    "        \"overlay\": overlay_path,\n",
    "        \"probabilities\": prob_path,\n",
    "        \"graph\": graph_path,\n",
    "        \"compartments\": compartment_path\n",
    "    },\n",
    "    \"graph_statistics\": {\n",
    "        \"num_nodes\": int(features.shape[0]),\n",
    "        \"num_edges\": int(np.sum(adjacency) // 2),\n",
    "        \"avg_degree\": float(np.sum(adjacency, axis=1).mean()),\n",
    "        \"feature_dim\": int(features.shape[1])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(OUTPUT_DIR, \"results\", \"reports\", \"demo_report.json\")\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "\n",
    "print(f\"âœ“ Report saved: {report_path}\")\n",
    "print(f\"\\nReport Summary:\")\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Pipeline Demo\n",
    "\n",
    "Now let's use the complete `ProteinLocalizationPipeline` class for end-to-end processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = ProteinLocalizationPipeline(output_dir=OUTPUT_DIR)\n",
    "\n",
    "print(\"âœ“ Pipeline initialized\")\n",
    "print(\"\\nPipeline ready for:\")\n",
    "print(\"  - Single image processing: pipeline.process_single_image(image_path)\")\n",
    "print(\"  - Batch processing: pipeline.process_batch(input_dir)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics Demo\n",
    "\n",
    "Demonstrate evaluation metrics computation (requires ground truth labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate predictions and ground truth for evaluation demo\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Generate synthetic predictions and ground truth\n",
    "y_true = np.random.randint(0, len(PROTEIN_CLASSES), n_samples)\n",
    "y_pred = y_true.copy()\n",
    "# Add some errors (15% error rate)\n",
    "error_indices = np.random.choice(n_samples, int(0.15 * n_samples), replace=False)\n",
    "y_pred[error_indices] = np.random.randint(0, len(PROTEIN_CLASSES), len(error_indices))\n",
    "\n",
    "# Compute metrics\n",
    "metrics = EvaluationMetrics.compute_metrics(y_true, y_pred, PROTEIN_CLASSES)\n",
    "\n",
    "print(\"Evaluation Metrics (on simulated data):\")\n",
    "print(f\"  Accuracy:    {metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision:   {metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:      {metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score:    {metrics['f1_score']:.4f}\")\n",
    "print(f\"  Specificity: {metrics['specificity']:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_path = os.path.join(GRAPHS_DIR, 'demo_confusion_matrix.png')\n",
    "EvaluationMetrics.plot_confusion_matrix(\n",
    "    np.array(metrics['confusion_matrix']), PROTEIN_CLASSES, cm_path,\n",
    "    title=\"Confusion Matrix - Simulated Data\"\n",
    ")\n",
    "print(f\"\\nâœ“ Confusion matrix saved: {cm_path}\")\n",
    "\n",
    "# Plot metrics comparison\n",
    "metrics_path = os.path.join(GRAPHS_DIR, 'demo_metrics.png')\n",
    "EvaluationMetrics.plot_metrics_comparison(metrics, metrics_path)\n",
    "print(f\"âœ“ Metrics comparison saved: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional Visualizations\n",
    "\n",
    "Demonstrate additional scientific visualization capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Grouped Bar Plot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data for grouped bar plot\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Nucleus': np.random.normal(0.85, 0.05, 20),\n",
    "    'Cytoplasm': np.random.normal(0.72, 0.08, 20),\n",
    "    'Membrane': np.random.normal(0.78, 0.06, 20),\n",
    "    'Mitochondria': np.random.normal(0.75, 0.07, 20)\n",
    "}\n",
    "\n",
    "bar_path = os.path.join(GRAPHS_DIR, 'demo_bar_plot.png')\n",
    "visualizer.plot_grouped_bars(\n",
    "    data, bar_path,\n",
    "    ylabel=\"Classification Confidence\",\n",
    "    title=\"Model Confidence by Protein Class\"\n",
    ")\n",
    "print(f\"âœ“ Grouped bar plot saved: {bar_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Violin/Box Plot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot with same data\n",
    "violin_path = os.path.join(GRAPHS_DIR, 'demo_violin_plot.png')\n",
    "visualizer.plot_violin_box(\n",
    "    data, violin_path,\n",
    "    ylabel=\"Classification Confidence\",\n",
    "    title=\"Confidence Distribution by Protein Class\"\n",
    ")\n",
    "print(f\"âœ“ Violin/box plot saved: {violin_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Colocalization Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two synthetic channels for colocalization\n",
    "channel1 = create_synthetic_neuron_image(size=(256, 256))\n",
    "channel2 = channel1 * 0.8 + np.random.normal(0, 0.1, (256, 256))  # Correlated channel\n",
    "channel2 = np.clip(channel2, 0, 1)\n",
    "\n",
    "# Compute colocalization metrics\n",
    "coloc_metrics = compute_colocalization_metrics(channel1, channel2)\n",
    "\n",
    "print(\"Colocalization Metrics:\")\n",
    "print(f\"  Pearson coefficient: {coloc_metrics['pearson_coefficient']:.4f}\")\n",
    "print(f\"  Manders M1:          {coloc_metrics['manders_M1']:.4f}\")\n",
    "print(f\"  Manders M2:          {coloc_metrics['manders_M2']:.4f}\")\n",
    "\n",
    "# Visualize colocalization\n",
    "coloc_path = os.path.join(GRAPHS_DIR, 'demo_colocalization.png')\n",
    "visualizer.plot_colocalization_scatter(\n",
    "    channel1, channel2, coloc_path,\n",
    "    title=\"Channel Colocalization Analysis\"\n",
    ")\n",
    "print(f\"âœ“ Colocalization plot saved: {coloc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing Example\n",
    "\n",
    "Demonstrate how to process multiple images in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batch Processing Instructions:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTo process all TIFF files in a directory:\")\n",
    "print(\"\\n  results = pipeline.process_batch(input_dir=INPUT_DIR)\")\n",
    "print(\"\\nThe pipeline will:\")\n",
    "print(\"  1. Recursively scan for .tif and .tiff files\")\n",
    "print(\"  2. Process each image through the complete pipeline\")\n",
    "print(\"  3. Save all outputs (segmentation, predictions, reports)\")\n",
    "print(\"  4. Generate a batch summary JSON report\")\n",
    "print(\"\\nOutput locations:\")\n",
    "print(f\"  - Segmented images: {OUTPUT_DIR}/results/segmented/\")\n",
    "print(f\"  - Reports: {OUTPUT_DIR}/results/reports/\")\n",
    "print(f\"  - Visualizations: {GRAPHS_DIR}/\")\n",
    "print(f\"  - Batch summary: {OUTPUT_DIR}/results/reports/batch_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Fusion Strategies\n",
    "\n",
    "Compare different fusion strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparing Fusion Strategies:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fusion_methods = [\n",
    "    (\"Average\", ModelFusion.late_fusion_average),\n",
    "    (\"Weighted (0.6/0.4)\", lambda c, g: ModelFusion.late_fusion_weighted(c, g, 0.6, 0.4)),\n",
    "    (\"Maximum\", ModelFusion.late_fusion_max),\n",
    "    (\"Geometric Mean\", ModelFusion.late_fusion_geometric_mean)\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, fusion_func in fusion_methods:\n",
    "    fused_cls, fused_prob = fusion_func(cnn_probs, gnn_probs)\n",
    "    results.append({\n",
    "        'method': name,\n",
    "        'class': PROTEIN_CLASSES[fused_cls],\n",
    "        'confidence': fused_prob[fused_cls]\n",
    "    })\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Predicted: {PROTEIN_CLASSES[fused_cls]}\")\n",
    "    print(f\"  Confidence: {fused_prob[fused_cls]:.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "methods = [r['method'] for r in results]\n",
    "confidences = [r['confidence'] for r in results]\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(methods)))\n",
    "\n",
    "bars = ax.bar(methods, confidences, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax.set_ylabel('Confidence', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Fusion Strategy Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "           f'{height:.3f}',\n",
    "           ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(GRAPHS_DIR, 'demo_fusion_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Fusion comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE DEMONSTRATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ“ Successfully demonstrated:\")\n",
    "print(\"  1. Image loading and preprocessing\")\n",
    "print(\"  2. Segmentation (SLIC superpixels)\")\n",
    "print(\"  3. CNN classification (VGG16)\")\n",
    "print(\"  4. Graph construction from superpixels\")\n",
    "print(\"  5. GNN classification (GCN)\")\n",
    "print(\"  6. Model fusion (multiple strategies)\")\n",
    "print(\"  7. Evaluation metrics computation\")\n",
    "print(\"  8. Scientific visualization generation\")\n",
    "print(\"  9. JSON report creation\")\n",
    "\n",
    "print(\"\\nðŸ“ Generated outputs:\")\n",
    "print(f\"  - Visualizations: {GRAPHS_DIR}/\")\n",
    "print(f\"  - Report: {report_path}\")\n",
    "\n",
    "print(\"\\nðŸš€ To use in production:\")\n",
    "print(\"  1. Train models on real neuronal microscopy data\")\n",
    "print(\"  2. Save trained weights for CNN and GNN\")\n",
    "print(\"  3. Load weights before prediction\")\n",
    "print(\"  4. Process real TIFF images from microscope\")\n",
    "\n",
    "print(\"\\nðŸ“š For more information:\")\n",
    "print(\"  - README.md: Complete documentation\")\n",
    "print(\"  - QUICKSTART.md: Quick reference guide\")\n",
    "print(\"  - JOURNAL_PAPER.md: Academic paper (35,000 words)\")\n",
    "print(\"  - PROJECT_SUMMARY.md: Implementation details\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Thank you for using the Protein Localization System!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Configuration Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all configuration parameters\n",
    "print(\"Current Configuration:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDirectories:\")\n",
    "print(f\"  INPUT_PATH:  {INPUT_PATH}\")\n",
    "print(f\"  OUTPUT_PATH: {OUTPUT_PATH}\")\n",
    "print(f\"  GRAPHS_PATH: {GRAPH_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\nImage Processing:\")\n",
    "print(f\"  IMAGE_SIZE:  {IMAGE_SIZE}\")\n",
    "print(f\"  BATCH_SIZE:  {BATCH_SIZE}\")\n",
    "\n",
    "print(f\"\\nSegmentation:\")\n",
    "print(f\"  METHOD:           {SEGMENTATION_METHOD}\")\n",
    "print(f\"  SLIC_N_SEGMENTS:  {SLIC_N_SEGMENTS}\")\n",
    "print(f\"  SLIC_COMPACTNESS: {SLIC_COMPACTNESS}\")\n",
    "\n",
    "print(f\"\\nGNN Architecture:\")\n",
    "print(f\"  HIDDEN_DIM:  {GNN_HIDDEN_DIM}\")\n",
    "print(f\"  NUM_LAYERS:  {GNN_NUM_LAYERS}\")\n",
    "print(f\"  DROPOUT:     {GNN_DROPOUT}\")\n",
    "\n",
    "print(f\"\\nVisualization:\")\n",
    "print(f\"  DPI:         {DPI}\")\n",
    "print(f\"  FIGURE_SIZE: {FIGURE_SIZE}\")\n",
    "print(f\"  COLORMAP:    {COLORMAP}\")\n",
    "\n",
    "print(f\"\\nProtein Classes ({len(PROTEIN_CLASSES)}):\")\n",
    "for i, cls in enumerate(PROTEIN_CLASSES, 1):\n",
    "    print(f\"  {i}. {cls}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
