{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Sub-Cellular Localization in Neurons\n",
    "\n",
    "This notebook demonstrates the complete pipeline for processing and analyzing TIFF images from the OpenCell database to predict protein sub-cellular localization patterns.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Environment Setup**\n",
    "2. **Data Access & Sanity Checks**\n",
    "3. **Image Preprocessing**\n",
    "4. **Graph Construction**\n",
    "5. **Labels Preparation**\n",
    "6. **Model Design & Training**\n",
    "7. **Inference**\n",
    "8. **Evaluation & Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import pipeline modules\n",
    "from utils.data_loader import TIFFDataLoader\n",
    "from utils.preprocessor import ImagePreprocessor\n",
    "from utils.graph_builder import GraphBuilder\n",
    "from utils.visualizer import Visualizer\n",
    "\n",
    "# Setup matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Input directory: {config['data']['input_dir']}\")\n",
    "print(f\"  Output directory: {config['data']['output_dir']}\")\n",
    "print(f\"  Model type: {config['model']['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Access & Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data directory\n",
    "DATA_DIR = \"../data/raw\"  # Change this to your TIFF images directory\n",
    "\n",
    "# Initialize data loader\n",
    "loader = TIFFDataLoader(DATA_DIR)\n",
    "\n",
    "# Scan directory for TIFF files\n",
    "image_files = loader.scan_directory()\n",
    "\n",
    "print(f\"Found {len(image_files)} TIFF files\")\n",
    "print(\"\\nFirst 5 files:\")\n",
    "for f in image_files[:5]:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images with validation\n",
    "images = loader.load_all(validate=True)\n",
    "\n",
    "# Print summary statistics\n",
    "loader.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample image\n",
    "if images:\n",
    "    sample_name = list(images.keys())[0]\n",
    "    sample_image, sample_metadata = images[sample_name]\n",
    "    \n",
    "    visualizer = Visualizer(config['visualization'])\n",
    "    visualizer.visualize_image(sample_image, title=f\"Sample: {sample_name}\")\n",
    "    \n",
    "    print(f\"\\nImage metadata:\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = ImagePreprocessor(config['preprocessing'])\n",
    "\n",
    "# Extract image arrays\n",
    "image_arrays = {k: v[0] for k, v in images.items()}\n",
    "\n",
    "# Preprocess a single image for demonstration\n",
    "sample_name = list(image_arrays.keys())[0]\n",
    "original = image_arrays[sample_name]\n",
    "processed = preprocessor.preprocess(original, sample_name)\n",
    "\n",
    "print(f\"Original shape: {original.shape}, dtype: {original.dtype}\")\n",
    "print(f\"Processed shape: {processed.shape}, dtype: {processed.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preprocessing results\n",
    "visualizer.visualize_preprocessing(\n",
    "    original, \n",
    "    processed,\n",
    "    title=f\"Preprocessing: {sample_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all images\n",
    "processed_images = preprocessor.preprocess_batch(\n",
    "    image_arrays,\n",
    "    output_dir=config['data']['processed_dir']\n",
    ")\n",
    "\n",
    "print(f\"Preprocessed {len(processed_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph builder\n",
    "graph_builder = GraphBuilder(config['graph'])\n",
    "\n",
    "# Build graph from sample image\n",
    "sample_name = list(processed_images.keys())[0]\n",
    "sample_image = processed_images[sample_name]\n",
    "\n",
    "graph_data = graph_builder.build_graph(sample_image, sample_name)\n",
    "\n",
    "print(f\"Graph constructed:\")\n",
    "print(f\"  Number of nodes: {graph_data['num_nodes']}\")\n",
    "print(f\"  Node features shape: {graph_data['node_features'].shape}\")\n",
    "print(f\"  Number of edges: {graph_data['edges'].shape[1]}\")\n",
    "print(f\"  Edge features shape: {graph_data['edge_features'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segmentation\n",
    "visualizer.visualize_segmentation(\n",
    "    sample_image,\n",
    "    graph_data['segments'],\n",
    "    title=f\"Segmentation: {sample_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graphs for all images\n",
    "graphs = graph_builder.build_batch(\n",
    "    processed_images,\n",
    "    output_dir=config['data']['graph_dir']\n",
    ")\n",
    "\n",
    "print(f\"Built {len(graphs)} graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Training is typically done via the command line for better resource management.\n",
    "However, you can also train from the notebook if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training command\n",
    "print(\"To train the model, run:\")\n",
    "print(f\"  python ../train.py --data_dir {config['data']['graph_dir']} --model_type gnn --epochs 100\")\n",
    "print(\"\\nOr for quick testing with fewer epochs:\")\n",
    "print(f\"  python ../train.py --data_dir {config['data']['graph_dir']} --model_type gnn --epochs 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference\n",
    "\n",
    "Run inference on images using a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if trained model exists\n",
    "model_path = Path(config['data']['output_dir']) / 'models' / 'best_model.pth'\n",
    "\n",
    "if model_path.exists():\n",
    "    print(f\"✓ Model found: {model_path}\")\n",
    "    \n",
    "    # Import inference module\n",
    "    from inference import InferenceEngine\n",
    "    \n",
    "    # Initialize inference engine\n",
    "    engine = InferenceEngine(str(model_path), config)\n",
    "    \n",
    "    # Run inference\n",
    "    results = engine.predict_from_directory(DATA_DIR)\n",
    "    \n",
    "    print(f\"\\nGenerated predictions for {len(results)} images\")\n",
    "    \n",
    "    # Display sample predictions\n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i, (filename, result) in enumerate(list(results.items())[:5]):\n",
    "        print(f\"  {filename}:\")\n",
    "        print(f\"    Predicted class: {result['class_name']}\")\n",
    "        print(f\"    Confidence: {result['probabilities'].max():.4f}\")\n",
    "else:\n",
    "    print(f\"✗ Model not found: {model_path}\")\n",
    "    print(\"Please train the model first using train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If predictions are available, visualize results\n",
    "if 'results' in locals() and results:\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Count predictions per class\n",
    "    pred_counts = Counter([r['prediction'] for r in results.values()])\n",
    "    class_names = config['labels']['class_names']\n",
    "    \n",
    "    # Plot distribution\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    classes = [class_names[p] for p in sorted(pred_counts.keys())]\n",
    "    counts = [pred_counts[p] for p in sorted(pred_counts.keys())]\n",
    "    \n",
    "    ax.bar(classes, counts)\n",
    "    ax.set_xlabel('Predicted Localization Class')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Prediction Distribution')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nPredictions per class:\")\n",
    "    for class_name, count in zip(classes, counts):\n",
    "        print(f\"  {class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete protein sub-cellular localization pipeline:\n",
    "\n",
    "1. ✓ Loaded and validated TIFF images\n",
    "2. ✓ Preprocessed images (denoising, normalization, enhancement)\n",
    "3. ✓ Constructed graph representations\n",
    "4. ✓ Prepared data for training\n",
    "5. Model training (via command line)\n",
    "6. Inference on all samples\n",
    "7. Evaluation and visualization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Train the model: `python train.py --data_dir data/graphs`\n",
    "- Run inference: `python inference.py --model_path outputs/models/best_model.pth --input_dir data/raw`\n",
    "- Evaluate results: `python evaluate.py --predictions_dir outputs/results`\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- ✓ Batch processing of multiple TIFF files\n",
    "- ✓ Automatic graph construction from images\n",
    "- ✓ Flexible model architectures (GNN, CNN)\n",
    "- ✓ Complete evaluation pipeline\n",
    "- ✓ Ubuntu + Jupyter Lab compatible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
