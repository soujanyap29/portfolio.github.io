{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Sub-Cellular Localization in Neurons\n",
    "## Complete Pipeline for TIFF Image Analysis, Graph Construction, and Classification\n",
    "\n",
    "This notebook provides a complete, executable pipeline for:\n",
    "1. **Preprocessing**: TIFF loading, Cellpose segmentation, feature extraction\n",
    "2. **Graph Construction**: Building biological graphs for GNN analysis\n",
    "3. **Model Training**: Graph-CNN, VGG-16, and hybrid models\n",
    "4. **Visualization**: Publication-ready scientific figures\n",
    "5. **Prediction**: End-to-end inference on new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torch-geometric networkx scikit-learn scikit-image\n",
    "!pip install -q matplotlib seaborn pandas numpy tifffile scipy\n",
    "!pip install -q cellpose flask\n",
    "\n",
    "print(\"✓ All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from preprocessing import TIFFPreprocessor, preprocess_pipeline\n",
    "from graph_builder import BiologicalGraphBuilder, build_graphs_pipeline\n",
    "from models import ModelTrainer, train_model_pipeline\n",
    "from visualization import ProteinVisualization, create_visualizations\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"Using PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "INPUT_DIR = \"/mnt/d/5TH_SEM/CELLULAR/input\"\n",
    "OUTPUT_DIR = \"/mnt/d/5TH_SEM/CELLULAR/output\"\n",
    "\n",
    "# Create output directories\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_DIR + \"/models\").mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_DIR + \"/visualizations\").mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_DIR + \"/graphs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'input_dir': INPUT_DIR,\n",
    "    'output_dir': OUTPUT_DIR,\n",
    "    'cellpose_diameter': 30.0,\n",
    "    'distance_threshold': 50.0,\n",
    "    'k_neighbors': 5,\n",
    "    'num_classes': 5,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration set\")\n",
    "print(f\"Input directory: {INPUT_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "### Load TIFF files, perform segmentation, and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = TIFFPreprocessor(INPUT_DIR, OUTPUT_DIR)\n",
    "\n",
    "# Scan for TIFF files\n",
    "tiff_files = preprocessor.scan_tiff_files()\n",
    "print(f\"\\nFound {len(tiff_files)} TIFF files to process\")\n",
    "\n",
    "if len(tiff_files) > 0:\n",
    "    print(\"\\nFirst few files:\")\n",
    "    for i, f in enumerate(tiff_files[:5]):\n",
    "        print(f\"  {i+1}. {f.name}\")\n",
    "else:\n",
    "    print(\"⚠️  No TIFF files found. Creating synthetic data for demonstration...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all TIFF files (or create synthetic data if none found)\n",
    "if len(tiff_files) > 0:\n",
    "    processed_results = preprocessor.process_all_tiffs()\n",
    "else:\n",
    "    # Create synthetic data for demonstration\n",
    "    print(\"Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    synthetic_results = []\n",
    "    for i in range(5):\n",
    "        # Create synthetic image\n",
    "        img = np.random.rand(256, 256) * 255\n",
    "        img = img.astype(np.uint8)\n",
    "        \n",
    "        # Create synthetic masks\n",
    "        masks = np.zeros((256, 256), dtype=int)\n",
    "        for j in range(10):\n",
    "            y, x = np.random.randint(20, 236, 2)\n",
    "            rr, cc = np.ogrid[:256, :256]\n",
    "            mask = ((rr - y) ** 2 + (cc - x) ** 2) < 100\n",
    "            masks[mask] = j + 1\n",
    "        \n",
    "        # Create synthetic features\n",
    "        features = []\n",
    "        for label in range(1, 11):\n",
    "            features.append({\n",
    "                'label': label,\n",
    "                'centroid_y': np.random.rand() * 256,\n",
    "                'centroid_x': np.random.rand() * 256,\n",
    "                'distance_from_center': np.random.rand() * 100,\n",
    "                'area': np.random.rand() * 500 + 100,\n",
    "                'perimeter': np.random.rand() * 100 + 50,\n",
    "                'eccentricity': np.random.rand(),\n",
    "                'solidity': np.random.rand() * 0.3 + 0.7,\n",
    "                'mean_intensity': np.random.rand() * 200 + 50,\n",
    "                'max_intensity': np.random.rand() * 255,\n",
    "                'intensity_std': np.random.rand() * 30,\n",
    "                'extent': np.random.rand(),\n",
    "                'major_axis_length': np.random.rand() * 50,\n",
    "                'minor_axis_length': np.random.rand() * 30,\n",
    "                'orientation': np.random.rand() * np.pi,\n",
    "                'bbox_min_row': 0, 'bbox_min_col': 0,\n",
    "                'bbox_max_row': 256, 'bbox_max_col': 256\n",
    "            })\n",
    "        \n",
    "        synthetic_results.append({\n",
    "            'file_path': f'synthetic_{i}.tif',\n",
    "            'file_name': f'synthetic_{i}.tif',\n",
    "            'image_shape': (256, 256),\n",
    "            'masks': masks,\n",
    "            'features': features,\n",
    "            'segmentation_metadata': {'n_cells': 10, 'method': 'synthetic'},\n",
    "            'n_regions': len(features)\n",
    "        })\n",
    "    \n",
    "    processed_results = synthetic_results\n",
    "    print(f\"✓ Created {len(processed_results)} synthetic samples\")\n",
    "\n",
    "print(f\"\\n✓ Preprocessing complete: {len(processed_results)} files processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display preprocessing summary\n",
    "print(\"Preprocessing Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for i, result in enumerate(processed_results[:3]):\n",
    "    print(f\"\\nFile {i+1}: {result['file_name']}\")\n",
    "    print(f\"  Shape: {result['image_shape']}\")\n",
    "    print(f\"  Regions detected: {result['n_regions']}\")\n",
    "    print(f\"  Segmentation method: {result['segmentation_metadata']['method']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph Construction\n",
    "### Build biological graphs from segmented regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graphs for all processed results\n",
    "graph_builder = BiologicalGraphBuilder(\n",
    "    distance_threshold=CONFIG['distance_threshold'],\n",
    "    k_neighbors=CONFIG['k_neighbors']\n",
    ")\n",
    "\n",
    "graph_results = graph_builder.process_results(\n",
    "    processed_results,\n",
    "    OUTPUT_DIR + \"/graphs\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Graph construction complete: {len(graph_results)} graphs created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display graph statistics\n",
    "print(\"Graph Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for i, result in enumerate(graph_results[:3]):\n",
    "    print(f\"\\nGraph {i+1}: {result['file_name']}\")\n",
    "    print(f\"  Nodes: {result['n_nodes']}\")\n",
    "    print(f\"  Edges: {result['n_edges']}\")\n",
    "    print(f\"  Density: {result['n_edges'] / (result['n_nodes'] * (result['n_nodes'] - 1) / 2) if result['n_nodes'] > 1 else 0:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "### Train Graph-CNN for protein localization classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PyG data objects\n",
    "pyg_data_list = [result['pyg_data'] for result in graph_results]\n",
    "\n",
    "print(f\"Prepared {len(pyg_data_list)} graphs for training\")\n",
    "if len(pyg_data_list) > 0:\n",
    "    print(f\"Node features per graph: {pyg_data_list[0].x.shape[1]}\")\n",
    "    print(f\"Example graph: {pyg_data_list[0].num_nodes} nodes, {pyg_data_list[0].edge_index.shape[1]} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Graph-CNN model\n",
    "training_results = train_model_pipeline(\n",
    "    pyg_data_list,\n",
    "    OUTPUT_DIR,\n",
    "    model_type='graph_cnn',\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training metrics\n",
    "metrics = training_results['metrics']\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy:    {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision:   {metrics['precision']:.4f}\")\n",
    "print(f\"Recall:      {metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score:    {metrics['f1_score']:.4f}\")\n",
    "if 'specificity' in metrics:\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(np.array(metrics['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "### Create publication-ready scientific figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualization\n",
    "viz = ProteinVisualization(OUTPUT_DIR + \"/visualizations\")\n",
    "\n",
    "# Create visualizations for first few samples\n",
    "for i, (proc_result, graph_result) in enumerate(zip(processed_results[:3], graph_results[:3])):\n",
    "    base_name = Path(proc_result['file_name']).stem\n",
    "    \n",
    "    print(f\"\\nCreating visualizations for {base_name}...\")\n",
    "    \n",
    "    # Plot graph\n",
    "    G = graph_result['networkx_graph']\n",
    "    viz.plot_graph(G, filename=f\"{base_name}_graph.png\", show_labels=True)\n",
    "    \n",
    "    # Plot feature distributions\n",
    "    viz.plot_feature_distributions(\n",
    "        proc_result['features'],\n",
    "        filename=f\"{base_name}_features.png\"\n",
    "    )\n",
    "    \n",
    "    # Plot intensity profile\n",
    "    viz.plot_intensity_profile(\n",
    "        proc_result['features'],\n",
    "        filename=f\"{base_name}_intensity.png\"\n",
    "    )\n",
    "\n",
    "print(\"\\n✓ Visualizations created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "history = training_results['history']\n",
    "viz.plot_training_history(history, filename=\"training_history.png\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = np.array(metrics['confusion_matrix'])\n",
    "class_names = [f\"Class {i}\" for i in range(len(cm))]\n",
    "viz.plot_confusion_matrix(cm, class_names, filename=\"confusion_matrix.png\")\n",
    "\n",
    "print(\"✓ Training visualizations created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Demo\n",
    "### Demonstrate end-to-end prediction on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = Path(OUTPUT_DIR) / \"models\" / \"graph_cnn_model.pt\"\n",
    "\n",
    "if model_path.exists():\n",
    "    predictor = ModelTrainer(model_type='graph_cnn', num_classes=CONFIG['num_classes'])\n",
    "    predictor.load_model(str(model_path), num_node_features=pyg_data_list[0].x.shape[1])\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "else:\n",
    "    print(\"⚠️  Model not found\")\n",
    "    predictor = training_results['trainer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on first sample\n",
    "if len(pyg_data_list) > 0:\n",
    "    sample = pyg_data_list[0]\n",
    "    \n",
    "    predictor.model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample = sample.to(predictor.device)\n",
    "        \n",
    "        # Add batch dimension\n",
    "        from torch_geometric.data import Batch\n",
    "        batch_sample = Batch.from_data_list([sample])\n",
    "        \n",
    "        output = predictor.model(batch_sample)\n",
    "        pred = output.argmax(dim=1).item()\n",
    "        probs = torch.exp(output)[0]\n",
    "        confidence = probs[pred].item()\n",
    "    \n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Sample: {processed_results[0]['file_name']}\")\n",
    "    print(f\"Predicted Class: {pred}\")\n",
    "    print(f\"Confidence: {confidence * 100:.2f}%\")\n",
    "    print(\"\\nClass Probabilities:\")\n",
    "    for i, prob in enumerate(probs):\n",
    "        print(f\"  Class {i}: {prob.item() * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"No samples available for prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Export\n",
    "### Generate comprehensive summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary = {\n",
    "    'pipeline': 'Protein Sub-Cellular Localization',\n",
    "    'date': __import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'input_dir': INPUT_DIR,\n",
    "    'output_dir': OUTPUT_DIR,\n",
    "    'n_files_processed': len(processed_results),\n",
    "    'n_graphs_created': len(graph_results),\n",
    "    'model_type': 'Graph-CNN',\n",
    "    'metrics': metrics,\n",
    "    'config': CONFIG\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "import json\n",
    "summary_path = Path(OUTPUT_DIR) / \"pipeline_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Files processed: {summary['n_files_processed']}\")\n",
    "print(f\"Graphs created: {summary['n_graphs_created']}\")\n",
    "print(f\"Model accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"\\nAll outputs saved to: {OUTPUT_DIR}\")\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "print(\"\\n✓ Pipeline execution complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Web Interface Instructions\n",
    "\n",
    "To run the web interface for file uploads and predictions:\n",
    "\n",
    "```bash\n",
    "cd ../frontend\n",
    "python app.py\n",
    "```\n",
    "\n",
    "Then open your browser to: http://localhost:5000\n",
    "\n",
    "The web interface allows you to:\n",
    "- Upload TIFF files via drag-and-drop\n",
    "- View real-time processing status\n",
    "- See segmentation results\n",
    "- View graph visualizations\n",
    "- Get prediction results with confidence scores\n",
    "- Download all analysis outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
