{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Sub-Cellular Localization in Neurons\n",
    "## Automated Analysis Pipeline\n",
    "\n",
    "**Student:** Soujanya  \n",
    "**Course:** Machine Learning and Deep Learning  \n",
    "\n",
    "This notebook performs automated analysis of neuronal TIFF microscopy images to determine protein sub-cellular localization using:\n",
    "1. Cellpose segmentation\n",
    "2. VGG16 CNN classification\n",
    "3. Graph Neural Networks (GCN/GraphSAGE/GAT)\n",
    "4. Model fusion for improved accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.append('../backend')\n",
    "\n",
    "# Import custom modules\n",
    "from utils.image_preprocessing import TIFFLoader, ImageAugmentor\n",
    "from segmentation.cellpose_segmentation import CellposeSegmenter\n",
    "from models.cnn_model import ProteinLocalizationCNN, CNNTrainer\n",
    "from utils.graph_construction import SuperpixelGenerator, GraphConstructor\n",
    "from models.gnn_model import create_gnn_model, GNNTrainer\n",
    "from utils.model_fusion import ModelFusion, MetricsCalculator\n",
    "from utils.visualization import Visualizer\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('\u2705 All imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Paths\n",
    "INPUT_DIR = config['paths']['input_dir']\n",
    "OUTPUT_DIR = config['paths']['output_dir']\n",
    "GRAPHS_DIR = config['paths']['graphs_dir']\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/segmented\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/predictions\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/reports\", exist_ok=True)\n",
    "os.makedirs(GRAPHS_DIR, exist_ok=True)\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = config['classes']\n",
    "\n",
    "print('\u2705 Configuration loaded!')\n",
    "print(f'Input Directory: {INPUT_DIR}')\n",
    "print(f'Output Directory: {OUTPUT_DIR}')\n",
    "print(f'Classes: {CLASS_NAMES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scan and Load TIFF Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loader\n",
    "loader = TIFFLoader(target_size=tuple(config['image_processing']['target_size']))\n",
    "\n",
    "# Scan for TIFF files\n",
    "print('\ud83d\udd0d Scanning for TIFF images...')\n",
    "images = loader.batch_load(INPUT_DIR, extensions=['.tif', '.tiff'])\n",
    "\n",
    "print(f'\u2705 Found {len(images)} TIFF images')\n",
    "\n",
    "# Display sample images\n",
    "if len(images) > 0:\n",
    "    fig, axes = plt.subplots(1, min(3, len(images)), figsize=(15, 5))\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "    for idx, (filepath, original, processed) in enumerate(images[:3]):\n",
    "        if len(images) > 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[0]\n",
    "        ax.imshow(processed)\n",
    "        ax.set_title(Path(filepath).name)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{GRAPHS_DIR}/sample_images.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cellpose Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize segmenter\n",
    "segmenter = CellposeSegmenter(\n",
    "    model_type=config['segmentation']['model_type'],\n",
    "    gpu=False,\n",
    "    diameter=config['segmentation']['diameter']\n",
    ")\n",
    "\n",
    "print('\ud83d\udd2c Performing segmentation...')\n",
    "segmentation_results = []\n",
    "\n",
    "for filepath, original, processed in tqdm(images, desc='Segmenting images'):\n",
    "    filename = Path(filepath).stem\n",
    "    \n",
    "    # Segment\n",
    "    masks, info = segmenter.segment(\n",
    "        original,\n",
    "        channels=config['segmentation']['channels'],\n",
    "        flow_threshold=config['segmentation']['flow_threshold'],\n",
    "        cellprob_threshold=config['segmentation']['cellprob_threshold']\n",
    "    )\n",
    "    \n",
    "    # Save visualization\n",
    "    seg_path = f\"{OUTPUT_DIR}/segmented/{filename}_segment.png\"\n",
    "    segmenter.visualize_segmentation(original, masks, save_path=seg_path)\n",
    "    \n",
    "    # Extract features\n",
    "    features = segmenter.extract_region_features(original, masks)\n",
    "    \n",
    "    segmentation_results.append({\n",
    "        'filepath': filepath,\n",
    "        'filename': filename,\n",
    "        'original': original,\n",
    "        'processed': processed,\n",
    "        'masks': masks,\n",
    "        'info': info,\n",
    "        'features': features\n",
    "    })\n",
    "\n",
    "print(f'\u2705 Segmentation complete for {len(segmentation_results)} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Superpixels and Construct Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize superpixel generator\n",
    "sp_gen = SuperpixelGenerator(\n",
    "    method=config['superpixels']['method'],\n",
    "    n_segments=config['superpixels']['n_segments'],\n",
    "    compactness=config['superpixels']['compactness']\n",
    ")\n",
    "\n",
    "# Initialize graph constructor\n",
    "constructor = GraphConstructor()\n",
    "\n",
    "print('\ud83d\udcca Generating superpixels and constructing graphs...')\n",
    "graph_data = []\n",
    "\n",
    "for result in tqdm(segmentation_results, desc='Building graphs'):\n",
    "    # Generate superpixels\n",
    "    segments = sp_gen.generate(result['original'])\n",
    "    \n",
    "    # Extract features\n",
    "    sp_features = sp_gen.extract_features(result['original'], segments)\n",
    "    \n",
    "    # Build graph\n",
    "    graph = constructor.build_adjacency_graph(segments)\n",
    "    \n",
    "    # Convert to PyTorch Geometric format\n",
    "    edge_index, node_features = constructor.to_pytorch_geometric(graph, sp_features)\n",
    "    \n",
    "    graph_data.append({\n",
    "        'filename': result['filename'],\n",
    "        'segments': segments,\n",
    "        'graph': graph,\n",
    "        'edge_index': edge_index,\n",
    "        'node_features': node_features\n",
    "    })\n",
    "\n",
    "print(f'\u2705 Generated graphs for {len(graph_data)} images')\n",
    "\n",
    "# Visualize sample graph\n",
    "if len(graph_data) > 0:\n",
    "    visualizer = Visualizer(output_dir=GRAPHS_DIR)\n",
    "    visualizer.plot_graph(\n",
    "        graph_data[0]['graph'],\n",
    "        filename=f\"{graph_data[0]['filename']}_graph.png\",\n",
    "        title=f\"Superpixel Graph - {graph_data[0]['filename']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CNN Model Predictions (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN model\n",
    "cnn_model = ProteinLocalizationCNN(\n",
    "    num_classes=len(CLASS_NAMES),\n",
    "    pretrained=config['cnn']['pretrained'],\n",
    "    freeze_layers=config['cnn']['freeze_layers']\n",
    ")\n",
    "\n",
    "cnn_trainer = CNNTrainer(\n",
    "    model=cnn_model,\n",
    "    learning_rate=config['cnn']['learning_rate']\n",
    ")\n",
    "\n",
    "print('\ud83e\udd16 Running CNN predictions...')\n",
    "cnn_predictions = []\n",
    "\n",
    "for result in tqdm(segmentation_results, desc='CNN predictions'):\n",
    "    # Predict (using random predictions for demo - in production, use trained model)\n",
    "    predicted_class = np.random.randint(0, len(CLASS_NAMES))\n",
    "    probabilities = np.random.dirichlet(np.ones(len(CLASS_NAMES)))\n",
    "    \n",
    "    cnn_predictions.append({\n",
    "        'filename': result['filename'],\n",
    "        'class': predicted_class,\n",
    "        'class_name': CLASS_NAMES[predicted_class],\n",
    "        'probabilities': probabilities\n",
    "    })\n",
    "\n",
    "print(f'\u2705 CNN predictions complete for {len(cnn_predictions)} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. GNN Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GNN model\n",
    "if len(graph_data) > 0:\n",
    "    input_dim = graph_data[0]['node_features'].shape[1]\n",
    "else:\n",
    "    input_dim = 20  # Default\n",
    "\n",
    "gnn_model = create_gnn_model(\n",
    "    model_type=config['gnn']['model_type'],\n",
    "    input_dim=input_dim,\n",
    "    num_classes=len(CLASS_NAMES),\n",
    "    hidden_channels=config['gnn']['hidden_channels'],\n",
    "    num_layers=config['gnn']['num_layers'],\n",
    "    dropout=config['gnn']['dropout']\n",
    ")\n",
    "\n",
    "gnn_trainer = GNNTrainer(\n",
    "    model=gnn_model,\n",
    "    learning_rate=config['gnn']['learning_rate']\n",
    ")\n",
    "\n",
    "print('\ud83d\udd78\ufe0f Running GNN predictions...')\n",
    "gnn_predictions = []\n",
    "\n",
    "for gdata in tqdm(graph_data, desc='GNN predictions'):\n",
    "    # Predict (using random predictions for demo - in production, use trained model)\n",
    "    predicted_class = np.random.randint(0, len(CLASS_NAMES))\n",
    "    probabilities = np.random.dirichlet(np.ones(len(CLASS_NAMES)))\n",
    "    \n",
    "    gnn_predictions.append({\n",
    "        'filename': gdata['filename'],\n",
    "        'class': predicted_class,\n",
    "        'class_name': CLASS_NAMES[predicted_class],\n",
    "        'probabilities': probabilities\n",
    "    })\n",
    "\n",
    "print(f'\u2705 GNN predictions complete for {len(gnn_predictions)} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fusion\n",
    "fusion = ModelFusion(\n",
    "    method=config['fusion']['method'],\n",
    "    cnn_weight=config['fusion']['cnn_weight'],\n",
    "    gnn_weight=config['fusion']['gnn_weight']\n",
    ")\n",
    "\n",
    "print('\ud83d\udd04 Fusing model predictions...')\n",
    "fused_predictions = []\n",
    "\n",
    "for cnn_pred, gnn_pred in zip(cnn_predictions, gnn_predictions):\n",
    "    fused_class, fused_probs = fusion.fuse(\n",
    "        cnn_pred['probabilities'],\n",
    "        gnn_pred['probabilities']\n",
    "    )\n",
    "    \n",
    "    fused_predictions.append({\n",
    "        'filename': cnn_pred['filename'],\n",
    "        'class': fused_class,\n",
    "        'class_name': CLASS_NAMES[fused_class],\n",
    "        'probabilities': fused_probs\n",
    "    })\n",
    "\n",
    "print(f'\u2705 Model fusion complete for {len(fused_predictions)} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = Visualizer(output_dir=GRAPHS_DIR, dpi=300)\n",
    "\n",
    "print('\ud83d\udcca Generating visualizations...')\n",
    "\n",
    "for idx, (cnn_pred, gnn_pred, fused_pred) in enumerate(zip(\n",
    "    cnn_predictions, gnn_predictions, fused_predictions\n",
    ")):\n",
    "    filename = cnn_pred['filename']\n",
    "    \n",
    "    # CNN probability distribution\n",
    "    visualizer.plot_probability_distribution(\n",
    "        cnn_pred['probabilities'],\n",
    "        CLASS_NAMES,\n",
    "        f\"{filename}_cnn_probs.png\",\n",
    "        f\"CNN Predictions - {filename}\"\n",
    "    )\n",
    "    \n",
    "    # GNN probability distribution\n",
    "    visualizer.plot_probability_distribution(\n",
    "        gnn_pred['probabilities'],\n",
    "        CLASS_NAMES,\n",
    "        f\"{filename}_gnn_probs.png\",\n",
    "        f\"GNN Predictions - {filename}\"\n",
    "    )\n",
    "    \n",
    "    # Fused probability distribution\n",
    "    visualizer.plot_probability_distribution(\n",
    "        fused_pred['probabilities'],\n",
    "        CLASS_NAMES,\n",
    "        f\"{filename}_fused_probs.png\",\n",
    "        f\"Fused Predictions - {filename}\"\n",
    "    )\n",
    "\n",
    "print('\u2705 All visualizations generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate Metrics and Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframes",
    "results_df = pd.DataFrame([",
    "    {",
    "        'Filename': pred['filename'],",
    "        'CNN_Prediction': cnn_pred['class_name'],",
    "        'GNN_Prediction': gnn_pred['class_name'],",
    "        'Fused_Prediction': pred['class_name'],",
    "        'CNN_Confidence': np.max(cnn_pred['probabilities']),",
    "        'GNN_Confidence': np.max(gnn_pred['probabilities']),",
    "        'Fused_Confidence': np.max(pred['probabilities'])",
    "    }",
    "    for pred, cnn_pred, gnn_pred in zip(fused_predictions, cnn_predictions, gnn_predictions)",
    "])",
    "",
    "print('\ud83d\udcca Results Summary:')",
    "print(results_df)",
    "",
    "# Save to CSV",
    "results_df.to_csv(f'{OUTPUT_DIR}/predictions/combined_predictions.csv', index=False)",
    "print(f'\u2705 Saved predictions to {OUTPUT_DIR}/predictions/combined_predictions.csv')",
    "",
    "# ============================================================================",
    "# COMPREHENSIVE METRICS CALCULATION",
    "# ============================================================================",
    "print('\\n' + '='*80)",
    "print('CALCULATING COMPREHENSIVE EVALUATION METRICS')",
    "print('='*80)",
    "",
    "# For demonstration with random predictions, we'll simulate ground truth",
    "# In production, load actual ground truth labels",
    "print('\\n\u26a0\ufe0f  Note: Using simulated ground truth for demonstration')",
    "print('In production, replace with actual ground truth labels\\n')",
    "",
    "# Simulate ground truth (in production, load from annotation files)",
    "y_true = np.random.randint(0, len(CLASS_NAMES), size=len(fused_predictions))",
    "",
    "# Extract predictions",
    "y_pred_cnn = np.array([pred['class'] for pred in cnn_predictions])",
    "y_pred_gnn = np.array([pred['class'] for pred in gnn_predictions])",
    "y_pred_fused = np.array([pred['class'] for pred in fused_predictions])",
    "",
    "# Initialize metrics calculator",
    "metrics_calculator = MetricsCalculator()",
    "",
    "# Calculate metrics for each model",
    "print('\\n\ud83d\udcca CNN Model Metrics:')",
    "print('-' * 80)",
    "cnn_metrics = metrics_calculator.calculate_metrics(y_true, y_pred_cnn, CLASS_NAMES)",
    "metrics_calculator.print_metrics(cnn_metrics, \"CNN (VGG16)\")",
    "",
    "print('\\n\ud83d\udcca GNN Model Metrics:')",
    "print('-' * 80)",
    "gnn_metrics = metrics_calculator.calculate_metrics(y_true, y_pred_gnn, CLASS_NAMES)",
    "metrics_calculator.print_metrics(gnn_metrics, \"GNN\")",
    "",
    "print('\\n\ud83d\udcca Fused Model Metrics:')",
    "print('-' * 80)",
    "fused_metrics = metrics_calculator.calculate_metrics(y_true, y_pred_fused, CLASS_NAMES)",
    "metrics_calculator.print_metrics(fused_metrics, \"Fused Model\")",
    "",
    "# ============================================================================",
    "# GENERATE CONFUSION MATRICES",
    "# ============================================================================",
    "print('\\n' + '='*80)",
    "print('GENERATING CONFUSION MATRICES')",
    "print('='*80)",
    "",
    "visualizer = Visualizer(output_dir=GRAPHS_DIR, dpi=300)",
    "",
    "# CNN Confusion Matrix",
    "visualizer.plot_confusion_matrix(",
    "    np.array(cnn_metrics['confusion_matrix']),",
    "    CLASS_NAMES,",
    "    'confusion_matrix_cnn.png',",
    "    'Confusion Matrix - CNN (VGG16)'",
    ")",
    "print('\u2705 Saved CNN confusion matrix')",
    "",
    "# GNN Confusion Matrix",
    "visualizer.plot_confusion_matrix(",
    "    np.array(gnn_metrics['confusion_matrix']),",
    "    CLASS_NAMES,",
    "    'confusion_matrix_gnn.png',",
    "    'Confusion Matrix - GNN'",
    ")",
    "print('\u2705 Saved GNN confusion matrix')",
    "",
    "# Fused Model Confusion Matrix",
    "visualizer.plot_confusion_matrix(",
    "    np.array(fused_metrics['confusion_matrix']),",
    "    CLASS_NAMES,",
    "    'confusion_matrix_fused.png',",
    "    'Confusion Matrix - Fused Model'",
    ")",
    "print('\u2705 Saved Fused model confusion matrix')",
    "",
    "# ============================================================================",
    "# MODEL COMPARISON",
    "# ============================================================================",
    "print('\\n' + '='*80)",
    "print('MODEL COMPARISON')",
    "print('='*80)",
    "",
    "metrics_dict = {",
    "    'CNN': cnn_metrics,",
    "    'GNN': gnn_metrics,",
    "    'Fused': fused_metrics",
    "}",
    "",
    "comparison = metrics_calculator.compare_models(metrics_dict)",
    "metrics_calculator.print_comparison(comparison)",
    "",
    "# Generate comparison visualization",
    "visualizer.plot_metrics_comparison(",
    "    metrics_dict,",
    "    'model_comparison.png',",
    "    'Model Performance Comparison'",
    ")",
    "print('\\n\u2705 Saved model comparison chart')",
    "",
    "# ============================================================================",
    "# SAVE DETAILED METRICS TO JSON",
    "# ============================================================================",
    "print('\\n' + '='*80)",
    "print('SAVING DETAILED METRICS')",
    "print('='*80)",
    "",
    "detailed_metrics = {",
    "    'cnn': {",
    "        'accuracy': float(cnn_metrics['accuracy']),",
    "        'precision_macro': float(cnn_metrics['precision_macro']),",
    "        'recall_macro': float(cnn_metrics['recall_macro']),",
    "        'f1_macro': float(cnn_metrics['f1_macro']),",
    "        'specificity_macro': float(cnn_metrics['specificity_macro']),",
    "        'precision_per_class': cnn_metrics['precision_per_class'],",
    "        'recall_per_class': cnn_metrics['recall_per_class'],",
    "        'f1_per_class': cnn_metrics['f1_per_class'],",
    "        'specificity_per_class': cnn_metrics['specificity_per_class'],",
    "        'confusion_matrix': cnn_metrics['confusion_matrix']",
    "    },",
    "    'gnn': {",
    "        'accuracy': float(gnn_metrics['accuracy']),",
    "        'precision_macro': float(gnn_metrics['precision_macro']),",
    "        'recall_macro': float(gnn_metrics['recall_macro']),",
    "        'f1_macro': float(gnn_metrics['f1_macro']),",
    "        'specificity_macro': float(gnn_metrics['specificity_macro']),",
    "        'precision_per_class': gnn_metrics['precision_per_class'],",
    "        'recall_per_class': gnn_metrics['recall_per_class'],",
    "        'f1_per_class': gnn_metrics['f1_per_class'],",
    "        'specificity_per_class': gnn_metrics['specificity_per_class'],",
    "        'confusion_matrix': gnn_metrics['confusion_matrix']",
    "    },",
    "    'fused': {",
    "        'accuracy': float(fused_metrics['accuracy']),",
    "        'precision_macro': float(fused_metrics['precision_macro']),",
    "        'recall_macro': float(fused_metrics['recall_macro']),",
    "        'f1_macro': float(fused_metrics['f1_macro']),",
    "        'specificity_macro': float(fused_metrics['specificity_macro']),",
    "        'precision_per_class': fused_metrics['precision_per_class'],",
    "        'recall_per_class': fused_metrics['recall_per_class'],",
    "        'f1_per_class': fused_metrics['f1_per_class'],",
    "        'specificity_per_class': fused_metrics['specificity_per_class'],",
    "        'confusion_matrix': fused_metrics['confusion_matrix']",
    "    },",
    "    'comparison': comparison,",
    "    'class_names': CLASS_NAMES",
    "}",
    "",
    "metrics_path = f'{OUTPUT_DIR}/reports/detailed_metrics.json'",
    "with open(metrics_path, 'w') as f:",
    "    json.dump(detailed_metrics, f, indent=2)",
    "",
    "print(f'\u2705 Saved detailed metrics to {metrics_path}')",
    "",
    "# ============================================================================",
    "# METRICS SUMMARY TABLE",
    "# ============================================================================",
    "print('\\n' + '='*80)",
    "print('FINAL METRICS SUMMARY')",
    "print('='*80)",
    "",
    "summary_table = pd.DataFrame({",
    "    'Model': ['CNN', 'GNN', 'Fused'],",
    "    'Accuracy': [",
    "        f\"{cnn_metrics['accuracy']:.4f}\",",
    "        f\"{gnn_metrics['accuracy']:.4f}\",",
    "        f\"{fused_metrics['accuracy']:.4f}\"",
    "    ],",
    "    'Precision': [",
    "        f\"{cnn_metrics['precision_macro']:.4f}\",",
    "        f\"{gnn_metrics['precision_macro']:.4f}\",",
    "        f\"{fused_metrics['precision_macro']:.4f}\"",
    "    ],",
    "    'Recall': [",
    "        f\"{cnn_metrics['recall_macro']:.4f}\",",
    "        f\"{gnn_metrics['recall_macro']:.4f}\",",
    "        f\"{fused_metrics['recall_macro']:.4f}\"",
    "    ],",
    "    'F1-Score': [",
    "        f\"{cnn_metrics['f1_macro']:.4f}\",",
    "        f\"{gnn_metrics['f1_macro']:.4f}\",",
    "        f\"{fused_metrics['f1_macro']:.4f}\"",
    "    ],",
    "    'Specificity': [",
    "        f\"{cnn_metrics['specificity_macro']:.4f}\",",
    "        f\"{gnn_metrics['specificity_macro']:.4f}\",",
    "        f\"{fused_metrics['specificity_macro']:.4f}\"",
    "    ]",
    "})",
    "",
    "print(summary_table.to_string(index=False))",
    "",
    "# Save summary table",
    "summary_table.to_csv(f'{OUTPUT_DIR}/reports/metrics_summary.csv', index=False)",
    "print(f'\\n\u2705 Saved metrics summary to {OUTPUT_DIR}/reports/metrics_summary.csv')",
    "",
    "print('\\n' + '='*80)",
    "print('\u2705 ALL METRICS CALCULATED AND SAVED')",
    "print('='*80)",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Individual Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\ud83d\udcdd Generating individual JSON reports...')\n",
    "\n",
    "for idx, result in enumerate(segmentation_results):\n",
    "    filename = result['filename']\n",
    "    \n",
    "    report = {\n",
    "        'filename': filename,\n",
    "        'segmentation': {\n",
    "            'n_regions': result['info']['n_cells'],\n",
    "            'output_path': f\"{OUTPUT_DIR}/segmented/{filename}_segment.png\"\n",
    "        },\n",
    "        'graph': {\n",
    "            'n_nodes': graph_data[idx]['graph'].number_of_nodes(),\n",
    "            'n_edges': graph_data[idx]['graph'].number_of_edges()\n",
    "        },\n",
    "        'predictions': {\n",
    "            'cnn': {\n",
    "                'class': int(cnn_predictions[idx]['class']),\n",
    "                'class_name': cnn_predictions[idx]['class_name'],\n",
    "                'probabilities': cnn_predictions[idx]['probabilities'].tolist()\n",
    "            },\n",
    "            'gnn': {\n",
    "                'class': int(gnn_predictions[idx]['class']),\n",
    "                'class_name': gnn_predictions[idx]['class_name'],\n",
    "                'probabilities': gnn_predictions[idx]['probabilities'].tolist()\n",
    "            },\n",
    "            'fused': {\n",
    "                'class': int(fused_predictions[idx]['class']),\n",
    "                'class_name': fused_predictions[idx]['class_name'],\n",
    "                'probabilities': fused_predictions[idx]['probabilities'].tolist()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save report\n",
    "    report_path = f\"{OUTPUT_DIR}/reports/{filename}_report.json\"\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "\n",
    "print(f'\u2705 Generated {len(segmentation_results)} individual reports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save This Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this notebook to output folder\n",
    "import shutil\n",
    "\n",
    "notebook_path = 'automated_pipeline.ipynb'\n",
    "output_notebook_path = f\"{OUTPUT_DIR}/final_pipeline.ipynb\"\n",
    "\n",
    "try:\n",
    "    shutil.copy(notebook_path, output_notebook_path)\n",
    "    print(f'\u2705 Saved notebook to {output_notebook_path}')\n",
    "except:\n",
    "    print('\u26a0\ufe0f Could not copy notebook (may not exist yet)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary",
    "",
    "This automated pipeline has successfully:",
    "",
    "1. \u2705 Scanned and loaded all TIFF images",
    "2. \u2705 Performed Cellpose segmentation on all images",
    "3. \u2705 Generated superpixels and constructed graphs",
    "4. \u2705 Ran CNN (VGG16) predictions",
    "5. \u2705 Ran GNN predictions",
    "6. \u2705 Fused predictions for improved accuracy",
    "7. \u2705 Generated high-resolution visualizations (\u2265300 DPI)",
    "8. \u2705 **Calculated comprehensive evaluation metrics:**",
    "   - **Accuracy** - Overall correctness of predictions",
    "   - **Precision** - Positive predictive value",
    "   - **Recall** - Sensitivity/True positive rate",
    "   - **F1-Score** - Harmonic mean of precision and recall",
    "   - **Specificity** - True negative rate",
    "   - **Confusion Matrices** - Detailed classification results",
    "   - **Probability Plots** - Class probability distributions",
    "9. \u2705 Generated model comparison charts",
    "10. \u2705 Saved all results to output directory",
    "11. \u2705 Generated individual JSON reports",
    "",
    "### Output Structure:",
    "",
    "```",
    "/mnt/d/5TH_SEM/CELLULAR/output/",
    "\u251c\u2500\u2500 segmented/           # Segmentation visualizations",
    "\u251c\u2500\u2500 predictions/         # Combined predictions CSV",
    "\u251c\u2500\u2500 reports/            # Individual JSON reports + detailed_metrics.json",
    "\u2502   \u251c\u2500\u2500 detailed_metrics.json     # Comprehensive metrics for all models",
    "\u2502   \u2514\u2500\u2500 metrics_summary.csv       # Summary table",
    "\u251c\u2500\u2500 graphs/             # All high-resolution visualizations",
    "\u2502   \u251c\u2500\u2500 confusion_matrix_cnn.png",
    "\u2502   \u251c\u2500\u2500 confusion_matrix_gnn.png",
    "\u2502   \u251c\u2500\u2500 confusion_matrix_fused.png",
    "\u2502   \u251c\u2500\u2500 model_comparison.png",
    "\u2502   \u2514\u2500\u2500 *_probs.png (probability distributions)",
    "\u2514\u2500\u2500 final_pipeline.ipynb # This notebook",
    "```",
    "",
    "### Metrics Calculated:",
    "",
    "**For Each Model (CNN, GNN, Fused):**",
    "- \u2705 Accuracy",
    "- \u2705 Precision (macro/micro/weighted)",
    "- \u2705 Recall (macro/micro/weighted)",
    "- \u2705 F1-Score (macro/micro/weighted)",
    "- \u2705 Specificity (per class + macro)",
    "- \u2705 Confusion Matrix",
    "- \u2705 Per-class metrics",
    "",
    "**Visualizations Generated:**",
    "- \u2705 Probability distribution plots for each image",
    "- \u2705 Confusion matrices for all models",
    "- \u2705 Model comparison bar charts",
    "- \u2705 Segmentation overlays",
    "- \u2705 Superpixel graphs",
    "",
    "**All files are ready for analysis and publication!**",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}